When transitioning from an IBM MQ-based messaging system to an API-based system, there are various risks, assumptions, and potential out-of-scope items to consider. Here's a breakdown:

### Risks:

1. **Integration Complexity**: The complexity of the new integration could be underestimated, leading to unexpected development and troubleshooting time.
2. **Data Format Conversion**: EDIFACT message processing and conversion could introduce errors if not handled properly.
3. **System Incompatibility**: The existing system may not be fully compatible with the REST API, necessitating additional middleware or adapters.
4. **Performance Issues**: Increased latency or decreased throughput when switching from a queue-based system to API calls.
5. **API Limitations**: The partner's API may have limitations or restrictions (like rate limits or message size limits) that were not present in the MQ system.
6. **Error Handling**: Different error handling mechanisms between MQ and API systems could lead to unhandled exceptions or message loss.
7. **Security Concerns**: Transitioning to an API may introduce new security vulnerabilities or require additional security measures.
8. **Message Duplication or Loss**: During the transition, messages could be duplicated or lost if the new system isn't properly synchronized with the old one.
9. **Dependency Risks**: Dependencies on the partner's API availability and performance, which are not under your control.
10. **Testing**: Inadequate testing could lead to undetected issues in production.

### Assumptions:

1. **Availability of Documentation**: Complete and accurate API documentation from the partner is available.
2. **Stable API**: The partner's API is stable and not subject to frequent changes.
3. **Existing Queue Mechanism**: The current local queue system is capable of supporting the new IIB Service without major modifications.
4. **Message Compatibility**: Messages in the EDIFACT format are fully supported by the partner's API without loss of data fidelity.
5. **Infrastructure**: Sufficient infrastructure is in place to support the new integration with necessary scalability and security.
6. **Testing Environment**: A testing environment that closely mirrors production is available for end-to-end testing.
7. **Client Support**: Timely support from the client for environment access, configuration, and troubleshooting.

### Potential Out of Scope Items:

1. **End-to-End Testing**: While you may handle unit and integration testing, comprehensive end-to-end testing might be the client's responsibility.
2. **User Training**: Training end users on the new system may not be included in your scope.
3. **Monitoring Tools**: Implementing or updating monitoring tools to oversee the new API-based communication.
4. **Ongoing Support**: Post-deployment support and troubleshooting might be considered out of scope if not explicitly agreed upon.
5. **Performance Tuning**: Fine-tuning the system for optimal performance post-deployment.
6. **Security Audits**: Conducting security audits for the new API integration might be out of scope.
7. **Documentation**: Creating documentation for the new system unless specified.
8. **Compliance Checks**: Ensuring that the new API integration complies with industry standards or regulations.
9. **Data Migration**: Handling any data migration from the old system to the new API system.
10. **Fallback Mechanism**: Developing a fallback or rollback mechanism in case the new API integration fails.

It's critical to have clear communication with the client about these aspects to ensure that expectations are aligned and that there is a mutual understanding of the project's scope and responsibilities.

#!/bin/bash

kubectl get deployments --all-namespaces -o=jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.namespace}{"\t"}{.apiVersion}{"\n"}'



# Fetch pod details with their CPU and memory requests and limits
kubectl get pods --all-namespaces -o custom-columns=KEY:.metadata.namespace+"/"+.metadata.name,NAMESPACE:.metadata.namespace,POD:.metadata.name,CPU_REQUEST:.spec.containers[].resources.requests.cpu,MEMORY_REQUEST:.spec.containers[].resources.requests.memory,CPU_LIMIT:.spec.containers[].resources.limits.cpu,MEMORY_LIMIT:.spec.containers[].resources.limits.memory > /tmp/pods.csv

# Fetch metrics for all pods (actual usage)
kubectl top pods --all-namespaces | awk 'NR>1 {print $1"/"$2","$3","$4}' > /tmp/metrics.csv

# Merge the two CSV files based on the unique key
awk -F, 'NR==FNR{metrics[$1]=$2","$3;next} {print $0","(metrics[$1] ? metrics[$1] : ",")}' /tmp/metrics.csv /tmp/pods.csv \
  | grep -vE '^kube-system,|^kube-public,|^kube-node-lease,'

# Cleanup temporary files
rm /tmp/pods.csv
rm /tmp/metrics.csv



#!/bin/bash

# Fetch pod details with their CPU and memory requests and limits
kubectl get pods --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,POD:.metadata.name,CPU_REQUEST:.spec.containers[].resources.requests.cpu,MEMORY_REQUEST:.spec.containers[].resources.requests.memory,CPU_LIMIT:.spec.containers[].resources.limits.cpu,MEMORY_LIMIT:.spec.containers[].resources.limits.memory > /tmp/pods.csv

# Fetch metrics for all pods (actual usage)
kubectl top pods --all-namespaces | awk 'NR>1 {print $1","$2","$3","$4}' > /tmp/metrics.csv

# Combine the two CSV files based on pod name and namespace using awk
awk -F, 'NR==FNR{a[$1,$2]=$3","$4;next} {print $0","a[$1,$2]}' /tmp/metrics.csv /tmp/pods.csv \
  | grep -vE '^kube-system,|^kube-public,|^kube-node-lease,'

# Cleanup temporary files
rm /tmp/pods.csv
rm /tmp/metrics.csv

--

#!/bin/bash

# Fetch pod details
kubectl get pods --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,POD:.metadata.name > /tmp/pods.csv

# Fetch metrics for all pods
kubectl top pods --all-namespaces | awk 'NR>1 {print $1","$2","$3","$4}' > /tmp/metrics.csv

# Combine the two CSV files based on pod name and namespace using awk
awk -F, 'NR==FNR{a[$1,$2]=$3","$4;next} {print $0","a[$1,$2]}' /tmp/metrics.csv /tmp/pods.csv \
  | grep -vE '^kube-system,|^kube-public,|^kube-node-lease,'

# Cleanup temporary files
rm /tmp/pods.csv
rm /tmp/metrics.csv



#!/bin/bash

# Fetch pod details and metrics
kubectl get pods --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,POD:.metadata.name > /tmp/pods.csv
kubectl top pods --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,POD:.metadata.name,CPU:.usage.cpu,MEMORY:.usage.memory >> /tmp/metrics.csv

# Combine the two CSV files based on the pod name and namespace
awk -F, 'NR==FNR{a[$1,$2]=$3","$4;next} {print $0","a[$1,$2]}' /tmp/metrics.csv /tmp/pods.csv \
  | grep -vE '^kube-system,|^kube-public,|^kube-node-lease,'

# Cleanup temp files
rm /tmp/pods.csv
rm /tmp/metrics.csv



kubectl get pods --all-namespaces \
  -o custom-columns=\
NAMESPACE:.metadata.namespace,\
POD:.metadata.name,\
CPU_REQUEST:".spec.containers[].resources.requests.cpu",\
MEMORY_REQUEST:".spec.containers[].resources.requests.memory",\
CPU_LIMIT:".spec.containers[].resources.limits.cpu",\
MEMORY_LIMIT:".spec.containers[].resources.limits.memory" \
  | awk 'BEGIN {print "NAMESPACE,POD,CPU_REQUEST,MEMORY_REQUEST,CPU_LIMIT,MEMORY_LIMIT"} {print $1","$2","$3","$4","$5","$6}' \
  | grep -vE '^kube-system,|^kube-public,|^kube-node-lease,'



kubectl get pods --all-namespaces \
  --no-headers \
  -o custom-columns=\
NAMESPACE:.metadata.namespace,\
POD:.metadata.name,\
CPU_REQUEST:".spec.containers[].resources.requests.cpu",\
MEMORY_REQUEST:".spec.containers[].resources.requests.memory",\
CPU_LIMIT:".spec.containers[].resources.limits.cpu",\
MEMORY_LIMIT:".spec.containers[].resources.limits.memory" \
  | { echo "NAMESPACE POD CPU_REQUEST MEMORY_REQUEST CPU_LIMIT MEMORY_LIMIT"; cat; } \
  | grep -vE '^kube-system|^kube-public|^kube-node-lease'




kubectl get pods --all-namespaces \
  --no-headers \
  -o custom-columns=\
NAMESPACE:.metadata.namespace,\
POD:.metadata.name,\
CPU_REQUEST:.spec.containers[].resources.requests.cpu,\
MEMORY_REQUEST:.spec.containers[].resources.requests.memory,\
CPU_LIMIT:.spec.containers[].resources.limits.cpu,\
MEMORY_LIMIT:.spec.containers[].resources.limits.memory \
  | grep -vE '^kube-system|^kube-public|^kube-node-lease'
